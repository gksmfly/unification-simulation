import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import platform

# ==============================
# âœ… í•œê¸€ í°íŠ¸ ì„¤ì •
# ==============================
system_name = platform.system()
if system_name == 'Darwin':  # macOS
    mpl.rcParams['font.family'] = 'AppleGothic'
elif system_name == 'Windows':  # Windows
    mpl.rcParams['font.family'] = 'Malgun Gothic'
else:  # Linux (Streamlit Cloud)
    mpl.rcParams['font.family'] = 'DejaVu Sans'  # ê¸°ë³¸ í°íŠ¸ (í•œê¸€ ì§€ì›)
mpl.rcParams['axes.unicode_minus'] = False

# ==============================
# âœ… Haversine ê±°ë¦¬ ê³„ì‚° (km)
# ==============================
def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2
    return R * 2 * np.arcsin(np.sqrt(a))

# ==============================
# âœ… CSV ì½ê¸° (ì¸ì½”ë”© ìë™ ì‹œë„)
# ==============================
def read_csv_with_fallback(path):
    encodings_to_try = ['utf-8-sig', 'cp949', 'euc-kr', 'latin1']
    for enc in encodings_to_try:
        try:
            return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError:
            continue
        except Exception:
            continue
    st.error(f"âŒ CSV íŒŒì¼ ì¸ì½”ë”© ì‹¤íŒ¨: {path}")
    return pd.DataFrame()

# ==============================
# âœ… ì‹¤í–‰ í•¨ìˆ˜
# ==============================
def run():
    file_before = 'data/tongil_before.xlsx'
    file_after = 'data/tongil_after.xlsx'
    file_nk = 'data/nk_station_map.csv'

    # 1. í†µì¼ ì „ ë°ì´í„°
    df_before = pd.read_excel(file_before)
    df_before['ìœ„ë„(y)'] = pd.to_numeric(df_before['ìœ„ë„(y)'], errors='coerce')
    df_before['ê²½ë„(x)'] = pd.to_numeric(df_before['ê²½ë„(x)'], errors='coerce')
    df_before['ê±°ë¦¬(km)'] = pd.to_numeric(df_before['ê±°ë¦¬(km)'], errors='coerce')

    ê±°ë¦¬_list = []
    for idx in range(len(df_before)):
        if idx + 1 >= len(df_before):
            ê±°ë¦¬_list.append(0)
            continue
        lat1, lon1 = df_before.loc[idx, ['ìœ„ë„(y)', 'ê²½ë„(x)']]
        lat2, lon2 = df_before.loc[idx + 1, ['ìœ„ë„(y)', 'ê²½ë„(x)']]
        if not np.isnan(lat1) and not np.isnan(lon1) and not np.isnan(lat2) and not np.isnan(lon2):
            dist = haversine(lat1, lon1, lat2, lon2)
        else:
            dist = np.nan
        if pd.isna(df_before.loc[idx, 'ê±°ë¦¬(km)']):
            ê±°ë¦¬_list.append(dist)
        else:
            ê±°ë¦¬_list.append(df_before.loc[idx, 'ê±°ë¦¬(km)'])
    df_before['ê±°ë¦¬(km)'] = ê±°ë¦¬_list
    df_before['ì†ë„(km/h)'] = pd.to_numeric(df_before['ì†ë„(km/h)'], errors='coerce').fillna(34)
    df_before['ì‹œê°„(h)'] = df_before['ê±°ë¦¬(km)'] / df_before['ì†ë„(km/h)']

    # 2. í†µì¼ í›„ ë°ì´í„°
    df_after = pd.read_excel(file_after)
    df_after['ì†ë„(km/h)'] = pd.to_numeric(df_after['ì†ë„(km/h)'], errors='coerce')
    df_after['ì‹œê°„(h)'] = df_after['ê±°ë¦¬(km)'] / df_after['ì†ë„(km/h)']

    # 3. ë¶í•œì—­ ë°ì´í„°
    df_nk = read_csv_with_fallback(file_nk)
    target_nk_stations = ['íŒë¬¸ì—­', 'í‰ì‚°ì—­', 'ì‚¬ë¦¬ì›ì—­', 'êµ¬ì„±ì—­', 'ì‹ ì˜ì£¼ì—­']
    nk_filtered = df_nk[df_nk['ì§€ëª…'].isin(target_nk_stations)][['ì§€ëª…', 'Yì¢Œí‘œ', 'Xì¢Œí‘œ']]
    nk_filtered = nk_filtered.set_index('ì§€ëª…').loc[target_nk_stations].reset_index()

    distances = []
    for i in range(len(nk_filtered)-1):
        lat1, lon1 = nk_filtered.loc[i, ['Yì¢Œí‘œ', 'Xì¢Œí‘œ']]
        lat2, lon2 = nk_filtered.loc[i+1, ['Yì¢Œí‘œ', 'Xì¢Œí‘œ']]
        distances.append(haversine(lat1, lon1, lat2, lon2))

    df_nk_dist = pd.DataFrame({
        'ì¶œë°œì—­': target_nk_stations[:-1],
        'ë„ì°©ì—­': target_nk_stations[1:],
        'ê±°ë¦¬(km)': distances
    })
    df_nk_dist['ì†ë„(km/h)'] = 40
    df_nk_dist['ì‹œê°„(h)'] = df_nk_dist['ê±°ë¦¬(km)'] / df_nk_dist['ì†ë„(km/h)']

    # 4. ì—´ ë§ì¶”ê¸°
    df_after_full = pd.concat([
        df_after.rename(columns={'ì¶œë°œì—­': 'ì¶œë°œì§€', 'ë„ì°©ì—­': 'ë„ì°©ì§€'}),
        df_nk_dist.rename(columns={'ì¶œë°œì—­': 'ì¶œë°œì§€', 'ë„ì°©ì—­': 'ë„ì°©ì§€'})
    ], ignore_index=True)

    # 5. ì´í•© ë¹„êµ
    total_before_distance = df_before['ê±°ë¦¬(km)'].sum()
    total_before_time = df_before['ì‹œê°„(h)'].sum()
    total_after_distance = df_after_full['ê±°ë¦¬(km)'].sum()
    total_after_time = df_after_full['ì‹œê°„(h)'].sum()

    df_compare = pd.DataFrame({
        'êµ¬ë¶„': ['í†µì¼ ì „', 'í†µì¼ í›„'],
        'ì´ ê±°ë¦¬(km)': [total_before_distance, total_after_distance],
        'ì´ ì‹œê°„(h)': [total_before_time, total_after_time]
    }).round(2)

    # 6. ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(7,5))
    bars = ax.bar(df_compare['êµ¬ë¶„'], df_compare['ì´ ê±°ë¦¬(km)'], color=['#ff6b6b', '#4dabf7'], width=0.6)
    for i, bar in enumerate(bars):
        height = bar.get_height()
        hh = int(df_compare['ì´ ì‹œê°„(h)'][i])
        mm = int(round((df_compare['ì´ ì‹œê°„(h)'][i] - hh) * 60))
        ax.text(bar.get_x() + bar.get_width()/2, height + 50, f"{hh}h {mm}m",
                ha='center', va='bottom', fontsize=12, fontweight='bold')

    ax.set_ylabel('ì´ë™ê±°ë¦¬ (km)')
    ax.set_title('ë¶€ì‚° â†’ ì‹ ì˜ì£¼ ì´ë™ê±°ë¦¬ / ì†Œìš”ì‹œê°„ ë¹„êµ', fontsize=15, fontweight='bold')
    ax.set_ylim(0, max(df_compare['ì´ ê±°ë¦¬(km)']) * 1.2)
    ax.grid(axis='y', linestyle='--', alpha=0.5)
    fig.tight_layout()

    # ì¶œë ¥
    st.subheader("ğŸ“Š ë¶€ì‚° â†’ ì‹ ì˜ì£¼ ì´ë™ê±°ë¦¬ ë° ì†Œìš”ì‹œê°„ ë¹„êµ")
    st.pyplot(fig)
    st.dataframe(df_compare)

if __name__ == "__main__":
    run()
